# ============================================================
# PART 1 â€” Importsã€åˆå§‹åŒ–ã€è³‡æ–™åº«ã€èªéŸ³ï¼ˆWhisper/TTSï¼‰ã€RAG
# ============================================================

import os
import json
import io
import hashlib
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from datetime import datetime
from dotenv import load_dotenv
from openai import OpenAI
import streamlit as st
import librosa
import soundfile as sf

# è‡ªè¨‚æ¨¡çµ„
from resume_parser import parse_resume
from grader import grade_interview
from pdf_export import export_pdf
from html_export import export_html
from db import (
    init_db,
    save_candidate,
    save_interview,
    save_qa,
    save_scores,
    get_interviews,
    get_scores,
    get_qa,
)

# ====== åˆå§‹åŒ– ======
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise RuntimeError("è«‹åœ¨ .env ä¸­è¨­å®š OPENAI_API_KEY")

client = OpenAI(api_key=api_key)

# ====== å­—å‹è¨­å®š ======
matplotlib.rcParams["font.sans-serif"] = ["Microsoft JhengHei"]
matplotlib.rcParams["axes.unicode_minus"] = False

# ====== åˆå§‹åŒ–è³‡æ–™åº« ======
init_db()

# ============================================================
# ------------- èªéŸ³åŠŸèƒ½ï¼ˆWhisper + TTSï¼‰ ---------------------
# ============================================================


def speech_to_text(file):
    """
    Whisper èªéŸ³è¾¨è­˜ï¼ˆå›å‚³ Python dictï¼Œéœ€è¦ verbose_jsonï¼‰
    """
    resp = client.audio.transcriptions.create(
        model="whisper-1",
        file=file,
        response_format="verbose_json"
    )
    return resp.model_dump()   # â­ å›å‚³ dictï¼ˆä¸æ˜¯ Transcription ç‰©ä»¶ï¼‰


def synthesize_speech(text: str) -> bytes:
    """
    TTS â€” æ–‡å­—è½‰èªéŸ³
    """
    try:
        resp = client.audio.speech.create(
            model="gpt-4o-mini-tts",
            voice="alloy",
            input=text,
        )
        return resp.read()
    except Exception as e:
        st.error(f"TTS éŒ¯èª¤ï¼š{e}")
        return None


# ============================================================
# ----------- èªéŸ³ç‰¹å¾µåˆ†æï¼šWPM / Silence / Volume / Fillers ----
# ============================================================

FILLERS = ["å—¯", "å‘ƒ", "é‚£å€‹", "å°±æ˜¯", "like", "you know"]


def analyze_speech_features(whisper_resp, audio_bytes):
    """
    å›å‚³ dictï¼š
    {
      wpm,
      silence_ratio,
      volume_stability,
      filler_ratio
    }
    """

    result = {}

    # -------------------------
    # 1) èªé€Ÿï¼ˆWPMï¼‰
    # -------------------------
    total_words = len(whisper_resp["text"].split())
    segs = whisper_resp["segments"]
    total_time = segs[-1]["end"] - segs[0]["start"]
    wpm = (total_words / total_time) * 60 if total_time > 0 else 0
    result["wpm"] = round(wpm, 2)

    # -------------------------
    # 2) åœé “æ¯”ä¾‹
    # -------------------------
    silences = []
    for i in range(1, len(segs)):
        gap = segs[i]["start"] - segs[i-1]["end"]
        if gap > 0.25:
            silences.append(gap)

    total_silence = sum(silences)
    result["silence_ratio"] = round(total_silence / total_time, 3)

    # -------------------------
    # 3) éŸ³é‡ç©©å®šåº¦ï¼ˆVolume Stabilityï¼‰
    # -------------------------
    y, sr = sf.read(io.BytesIO(audio_bytes))
    frame_energy = librosa.feature.rms(y=y)[0]

    vol_mean = np.mean(frame_energy)
    vol_std = np.std(frame_energy)

    stability = 1 - (vol_std / (vol_mean + 1e-9))
    result["volume_stability"] = round(float(stability), 3)

    # -------------------------
    # 4) å¡«å……è©æ¯”ä¾‹
    # -------------------------
    filler_count = sum(whisper_resp["text"].count(f) for f in FILLERS)
    filler_ratio = filler_count / max(total_words, 1)
    result["filler_ratio"] = round(filler_ratio, 3)

    return result


# ============================================================
# ------------- RAG çŸ¥è­˜åº«è¼‰å…¥ï¼ˆé›»è³‡å­¸ç”Ÿå°ˆç”¨ï¼‰ ---------------
# ============================================================

class SimpleRAG:
    def __init__(self, folder="knowledge"):
        self.docs = []
        if not os.path.isdir(folder):
            return
        for fname in os.listdir(folder):
            if fname.endswith((".md", ".txt")):
                with open(os.path.join(folder, fname), "r", encoding="utf-8") as f:
                    self.docs.append((fname, f.read()))

    def retrieve(self, job, query, top_k=3):
        if not self.docs:
            return []
        q = query.lower()
        scored = []
        for name, text in self.docs:
            score = sum(q.count(tok)
                        for tok in q.split() if tok in text.lower())
            scored.append((score, text))
        scored.sort(reverse=True, key=lambda x: x[0])
        return [x[1] for x in scored[:top_k] if x[0] > 0]


@st.cache_resource
def load_rag():
    return SimpleRAG("knowledge")


rag = load_rag()

# ============================================================
# -------------------- UI & Session åˆå§‹åŒ– -------------------
# ============================================================

st.set_page_config(page_title="AI è™›æ“¬é¢è©¦å®˜", page_icon="ğŸ§‘â€ğŸ«", layout="wide")


def local_css(file_name):
    with open(file_name) as f:
        st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)


local_css("static/style.css")

st.title("ğŸ§‘â€ğŸ« AI è™›æ“¬é¢è©¦å®˜")

# Custom CSS for new components
st.markdown("""
<style>
    /* Additional custom styles can be added here */
    .stTabs [data-baseweb="tab-list"] {
        gap: 24px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        white-space: pre-wrap;
        background-color: #F0F2F6;
        border-radius: 4px 4px 0px 0px;
        gap: 1px;
        padding-top: 10px;
        padding-bottom: 10px;
    }
    .stTabs [aria-selected="true"] {
        background-color: #FFFFFF;
    }
</style>""", unsafe_allow_html=True)


def init_state(key, value):
    if key not in st.session_state:
        st.session_state[key] = value


init_state("messages", [])
init_state("started", False)
init_state("resume_info", None)
init_state("candidate_id", "")
init_state("qa_list", [])
init_state("last_question", None)
init_state("grade_result", None)
init_state("selected_history_interview_id", None)
init_state("voice_mode", True)
init_state("play_tts_first_question", False)
init_state("last_speech_features", None)
init_state("last_audio_hash", None)
init_state("start_time", None)
init_state("time_limit_minutes", 10)
init_state("auto_end_reason", None)
init_state("etiquette_strikes", 0)
init_state("qualified_streak", 0)

# ============================================================
# PART 2 â€” å±¥æ­·è§£æã€Prompt ç”Ÿæˆã€RAGã€LLM å›è¦†
# ============================================================

# ------------------------------------------------------------
# Sidebar è¨­ç½®
# ------------------------------------------------------------
with st.sidebar:
    st.header("é¢è©¦è¨­å®š")

    # å—è©¦è€… ID
    candidate_id = st.text_input(
        "å—è©¦è€… IDï¼ˆå§“å / å­¸è™Ÿï¼‰", value=st.session_state.candidate_id)
    st.session_state.candidate_id = candidate_id

    if candidate_id:
        save_candidate(candidate_id)

    job_role = st.selectbox(
        "æ‡‰å¾µè·ç¼º",
        [
            "å¾Œç«¯å·¥ç¨‹å¸«",
            "AI å·¥ç¨‹å¸«",
            "è³‡æ–™å·¥ç¨‹å¸«",
            "å‰ç«¯å·¥ç¨‹å¸«",
            "éŸŒé«”å·¥ç¨‹å¸«",
            "ç¡¬é«”å·¥ç¨‹å¸«",
            "FPGA å·¥ç¨‹å¸«",
            "å°„é »å·¥ç¨‹å¸«",
            "é›»åŠ›é›»å­å·¥ç¨‹å¸«",
            "åµŒå…¥å¼ç³»çµ±å·¥ç¨‹å¸«",
        ]
    )
    st.session_state.job_role = job_role

    interview_style = st.selectbox(
        "é¢è©¦é¢¨æ ¼",
        ["æ™®é€š", "åš´æ ¼", "æº«å’Œ"]
    )
    st.session_state.interview_style = interview_style

    st.markdown("---")
    st.subheader("å±¥æ­·ä¸Šå‚³ï¼ˆPDFï¼‰")
    uploaded_resume = st.file_uploader("é¸æ“‡ PDF å±¥æ­·", type=["pdf"])

    st.caption("æç¤ºï¼šå¯å°‡å…¬å¸/ç”¢å“çŸ¥è­˜ä»¥ .md æˆ– .txt æ”¾å…¥ knowledge è³‡æ–™å¤¾ï¼Œç³»çµ±å°‡è‡ªå‹•è¼‰å…¥ã€‚")

    st.markdown("---")
    st.subheader("è‡ªå‹•çµæŸè¨­å®š")
    time_limit = st.slider(
        "è¶…éæ­¤åˆ†é˜æ•¸è‡ªå‹•çµæŸé¢è©¦",
        min_value=5,
        max_value=30,
        value=st.session_state.time_limit_minutes,
        step=1
    )
    st.session_state.time_limit_minutes = time_limit

    st.markdown("---")
    st.subheader("æ­·å²ç´€éŒ„")

    history = []
    if candidate_id:
        history = get_interviews(candidate_id)

    if history:
        options = [
            f"{h['timestamp']}ï½œ{h['job_role']}ï½œID:{h['interview_id']}"
            for h in history
        ]
        picked = st.selectbox("é¸æ“‡ä¸€ç­†æ­·å²ç´€éŒ„ï¼š", options)
        idx = options.index(picked)
        st.session_state.selected_history_interview_id = history[idx]["interview_id"]
    else:
        st.caption("å°šç„¡æ­·å²ç´€éŒ„")

    st.markdown("---")
    if st.button("ğŸ” é‡ç½®é¢è©¦"):
        for key in [
            "messages", "started", "resume_info", "qa_list",
            "last_question", "grade_result", "last_speech_features",
            "last_audio_hash", "start_time", "auto_end_reason",
            "etiquette_strikes", "qualified_streak"
        ]:
            st.session_state[key] = None if key == "resume_info" else []
        st.session_state.started = False
        st.rerun()


# ------------------------------------------------------------
# å±¥æ­·è§£æï¼ˆPDF â†’ JSONï¼‰
# ------------------------------------------------------------
if uploaded_resume and st.session_state.resume_info is None:
    with st.spinner("AI æ­£åœ¨è§£æä½ çš„å±¥æ­·â€¦"):
        st.session_state.resume_info = parse_resume(uploaded_resume)
    st.success("å±¥æ­·è§£æå®Œæˆï¼")

# å±•ç¤ºå±¥æ­·è§£æå…§å®¹
with st.expander("ğŸ“„ å±¥æ­·è§£æçµæœ"):
    ri = st.session_state.resume_info
    if ri:
        st.markdown("### ğŸ§© æŠ€èƒ½")
        st.write(", ".join(ri.get("skills", [])) or "ï¼ˆç„¡ï¼‰")

        st.markdown("### ğŸ“š å°ˆæ¡ˆ")
        for p in ri.get("projects", []):
            st.markdown(f"**{p['title']}** â€” {p['description']}")
            st.caption("æŠ€è¡“ï¼š" + ", ".join(p.get("tech_stack", [])))

        st.markdown("### ğŸ’¼ å·¥ä½œç¶“é©—")
        for w in ri.get("work_experience", []):
            st.markdown(
                f"**{w['company']} / {w['position']} ({w['duration']})**")
            st.write(w["description"])

        st.markdown("### ğŸ“ å­¸æ­·")
        for e in ri.get("education", []):
            st.markdown(f"- {e['school']} â€” {e['degree']} ({e['duration']})")

        st.markdown("### ğŸ“ è‡ªæˆ‘æ‘˜è¦")
        st.write(ri.get("summary", "ï¼ˆç„¡ï¼‰"))
    else:
        st.caption("å°šæœªä¸Šå‚³å±¥æ­·ã€‚")


# ------------------------------------------------------------
# Prompt å»ºæ§‹å™¨ï¼ˆå« RAGï¼‰
# ------------------------------------------------------------
def build_system_prompt(job, style, resume_info=None, rag_snippets=None):

    style_desc = {
        "æ™®é€š": "èªæ°£å°ˆæ¥­ï¼Œæå•è‡ªç„¶ã€‚",
        "åš´æ ¼": "èªæ°£ç›´æ¥ã€è¿½å•ç´°ç¯€ã€æœ‰å£“åŠ›æ„Ÿã€‚",
        "æº«å’Œ": "èªæ°£è¦ªåˆ‡ã€é¼“å‹µå¼æå•ã€‚",
    }[style]

    ROLE_COMPETENCIES = {
        "å¾Œç«¯å·¥ç¨‹å¸«": [
            "ç³»çµ±è¨­è¨ˆèˆ‡æ¶æ§‹å–æ¨ï¼ˆå¯ç”¨æ€§ã€å»¶å±•æ€§ã€å®‰å…¨ï¼‰",
            "è³‡æ–™åº«èˆ‡å¿«å–ï¼ˆSQL/NoSQL/ç´¢å¼•/äº¤æ˜“ï¼‰",
            "API è¨­è¨ˆèˆ‡æ•ˆèƒ½ï¼ˆREST/GraphQLã€è§€æ¸¬æ€§ã€CI/CDï¼‰",
            "ä½µç™¼èˆ‡å¯é æ€§ï¼ˆé–ã€é‡è©¦ã€æ’ç¨‹ã€ä½µç™¼æ¨¡å‹ï¼‰",
        ],
        "AI å·¥ç¨‹å¸«": [
            "æ¨¡å‹é¸å‹èˆ‡å¾®èª¿ï¼ˆLLMã€Transformerã€å‘é‡ç´¢å¼•ï¼‰",
            "RAG èˆ‡è³‡æ–™ç®¡ç·šï¼ˆæª¢ç´¢ã€Chunkã€Embeddingã€è©•ä¼°ï¼‰",
            "éƒ¨ç½²èˆ‡æ•ˆèƒ½ï¼ˆæ‰¹æ¬¡ã€é‡åŒ–ã€å¿«å–ã€å¯è§€æ¸¬æ€§ï¼‰",
            "è³‡æ–™èˆ‡å®‰å…¨ï¼ˆéš±ç§ã€æ¼‚ç§»ç›£æ§ã€è³‡æ–™å“è³ªï¼‰",
        ],
        "è³‡æ–™å·¥ç¨‹å¸«": [
            "è³‡æ–™ç®¡ç·šè¨­è¨ˆï¼ˆæ‰¹/æµã€é‡è©¦ã€å›å¡«ï¼‰",
            "å„²å­˜èˆ‡æ¨¡å‹ï¼ˆæ¹–å€‰ã€åˆ†å‰²ã€ç´¢å¼•ã€æ ¼å¼ï¼‰",
            "èª¿åº¦èˆ‡æ²»ç†ï¼ˆAirflow/å·¥ä½œæµã€å“è³ªã€è¡€ç·£ã€æˆæœ¬æ§ç®¡ï¼‰",
            "å¯ç”¨æ€§èˆ‡æ“´å±•ï¼ˆåˆ†æ•£å¼è™•ç†ã€å½ˆæ€§ã€ç›£æ§ï¼‰",
        ],
        "å‰ç«¯å·¥ç¨‹å¸«": [
            "æ¶æ§‹èˆ‡ç‹€æ…‹ç®¡ç†ï¼ˆReact/Vueã€è·¯ç”±ã€å¿«å–ç­–ç•¥ï¼‰",
            "æ€§èƒ½å„ªåŒ–ï¼ˆé¦–å±/åŒ…é«”ã€Lazy loadã€SSR/CSRï¼‰",
            "å¯ç”¨æ€§èˆ‡ç„¡éšœç¤™ï¼ˆa11yã€è¨­è¨ˆç³»çµ±ã€ä¸€è‡´æ€§ï¼‰",
            "å‰å¾Œç«¯å”ä½œèˆ‡æ¸¬è©¦ï¼ˆAPI å°é½Šã€E2E/å–®å…ƒæ¸¬è©¦ã€CIï¼‰",
        ],
        "éŸŒé«”å·¥ç¨‹å¸«": [
            "MCU/SoC æ¶æ§‹èˆ‡é©…å‹•é–‹ç™¼ï¼ˆI2C/SPI/UART/USBï¼‰",
            "RTOS/è£¸æ©Ÿè¨­è¨ˆï¼ˆæ’ç¨‹ã€ä¸­æ–·ã€ä½åŠŸè€—ï¼‰",
            "éŸŒé«”æ¸¬è©¦èˆ‡é‡ç”¢ï¼ˆDFU/OTAã€é‡æ¸¬ã€è‡ªå‹•åŒ–æ¸¬è©¦ï¼‰",
            "æ•ˆèƒ½èˆ‡å¯é åº¦ï¼ˆè¨˜æ†¶é«”/åŠŸè€—å„ªåŒ–ã€é™¤éŒ¯èˆ‡è¿½è¹¤ï¼‰",
        ],
        "ç¡¬é«”å·¥ç¨‹å¸«": [
            "é›»è·¯è¨­è¨ˆèˆ‡ä½ˆå±€ï¼ˆåŸç†åœ–ã€PCBã€SI/PIï¼‰",
            "å…ƒä»¶é¸å‹èˆ‡å¯é åº¦ï¼ˆDeratingã€EMI/EMCã€ESDï¼‰",
            "é‡æ¸¬é©—è­‰ï¼ˆç¤ºæ³¢å™¨ã€é »è­œåˆ†æã€ATEï¼‰",
            "é‡ç”¢å°å…¥ï¼ˆDFM/DFAã€BOM æˆæœ¬ã€è‰¯ç‡æ”¹å–„ï¼‰",
        ],
        "FPGA å·¥ç¨‹å¸«": [
            "RTL/HDL è¨­è¨ˆï¼ˆVerilog/VHDLï¼‰ã€æ™‚åºç´„æŸï¼ˆSDCï¼‰",
            "é«˜é€Ÿä»‹é¢èˆ‡ IPï¼ˆPCIeã€Ethernetã€DDRã€SerDesï¼‰",
            "é©—è­‰èˆ‡é™¤éŒ¯ï¼ˆä»¿çœŸã€é‚è¼¯åˆ†æã€LA/ILAï¼‰",
            "è³‡æº/åŠŸè€—/æ™‚åºå„ªåŒ–ï¼ˆP&Rã€floorplanningï¼‰",
        ],
        "å°„é »å·¥ç¨‹å¸«": [
            "RF å‰ç«¯è¨­è¨ˆï¼ˆPA/LNA/Filterã€åŒ¹é…ã€å¤©ç·šï¼‰",
            "é‡æ¸¬èˆ‡èª¿æ ¡ï¼ˆVNAã€é »è­œã€è«§æ³¢ã€éš”é›¢åº¦ï¼‰",
            "EMI/EMC èˆ‡æ³•è¦ï¼ˆèªè­‰æµç¨‹ã€æ•´æ”¹æ–¹æ¡ˆï¼‰",
            "ç³»çµ±æ•´åˆï¼ˆRF + Basebandã€å¹²æ“¾åˆ†æã€ç†±ç®¡ç†ï¼‰",
        ],
        "é›»åŠ›é›»å­å·¥ç¨‹å¸«": [
            "é›»æºæ‹“æ’²èˆ‡æ§åˆ¶ï¼ˆBuck/Boostã€PFCã€LLCï¼‰",
            "ç£æ€§å…ƒä»¶èˆ‡æ•£ç†±ï¼ˆè®Šå£“å™¨/é›»æ„Ÿè¨­è¨ˆã€ç†±é˜»åˆ†æï¼‰",
            "ä¿è­·èˆ‡å¯é åº¦ï¼ˆOCP/OVP/OTPã€å®‰è¦èˆ‡èªè­‰ï¼‰",
            "æ•ˆç‡èˆ‡ EMI æœ€ä½³åŒ–ï¼ˆä½ˆå±€ã€è£œå„Ÿã€é–‹é—œæè€—ï¼‰",
        ],
        "åµŒå…¥å¼ç³»çµ±å·¥ç¨‹å¸«": [
            "ç³»çµ±æ•´åˆï¼ˆSensor/Actuatorã€é€šè¨ŠåŒ¯æµæ’ï¼‰",
            "ä½œæ¥­ç³»çµ±èˆ‡é©…å‹•ï¼ˆLinux/RTOSã€Device Treeã€é©…å‹•æ¨¡å‹ï¼‰",
            "æ•ˆèƒ½èˆ‡åŠŸè€—ï¼ˆCPU/GPU/åŠ é€Ÿå™¨ã€DVFSã€ä½åŠŸè€—æ¨¡å¼ï¼‰",
            "å®‰å…¨èˆ‡æ›´æ–°ï¼ˆSecure Bootã€OTAã€æ•…éšœå¾©åŸï¼‰",
        ],
    }

    # ===== å±¥æ­·å…§å®¹ =====
    resume_context = ""
    if resume_info:
        skills = resume_info.get("skills", [])
        resume_context += f"å€™é¸äººæŠ€èƒ½ï¼š{', '.join(skills)}\n" if skills else ""

        if resume_info.get("projects"):
            resume_context += "å°ˆæ¡ˆï¼š\n"
            for p in resume_info["projects"]:
                resume_context += f"- {p['title']}: {p['description']}\n"

    # ===== RAG =====
    rag_context = ""
    if rag_snippets:
        rag_context += "\nä»¥ä¸‹ç‚ºè·ç¼ºç›¸é—œçš„æŠ€è¡“çŸ¥è­˜ç‰‡æ®µï¼ˆRAGï¼‰ï¼š\n"
        for i, sn in enumerate(rag_snippets, 1):
            rag_context += f"[{i}] {sn}\n"

    competencies = ROLE_COMPETENCIES.get(job, [])
    comp_text = "\n".join(
        f"- {c}" for c in competencies) if competencies else ""

    return f"""
ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ **{job}** é¢è©¦å®˜ã€‚

é¢è©¦é¢¨æ ¼ï¼š{style_desc}

è©²è·ç¼ºæ ¸å¿ƒèƒ½åŠ›ï¼š
{comp_text}

è«‹éµå®ˆè¦å‰‡ï¼š
1. æ¯æ¬¡åªå•ä¸€é¡Œã€‚
2. å•é¡Œéœ€æœ‰æŠ€è¡“æ·±åº¦ï¼Œèšç„¦è·ç¼ºèƒ½åŠ›ã€‚
3. è‹¥å€™é¸äººç­”ä¸å®Œæ•´ï¼Œè¿½å•æ›´ç´°ã€‚
4. ç”¨ç¹é«”ä¸­æ–‡ã€‚

å€™é¸äººè³‡è¨Šï¼š
{resume_context}

æŠ€è¡“çŸ¥è­˜ï¼ˆRAGï¼‰ï¼š
{rag_context}

é–‹å§‹é¢è©¦ï¼Œè«‹æå‡ºç¬¬ä¸€é¡Œï¼šè‡ªæˆ‘ä»‹ç´¹ã€‚
""".strip()


# ------------------------------------------------------------
# LLM Response (with RAG query)
# ------------------------------------------------------------
def call_llm(job, style, history, resume_info=None):

    # ---- RAG æŸ¥è©¢å­—ä¸² ----
    query_parts = [f"è·ç¼ºï¼š{job}"]

    last_q = None
    last_a = None

    for role, msg in reversed(history):
        if role == "assistant" and last_q is None:
            last_q = msg
        elif role == "user" and last_a is None:
            last_a = msg
        if last_q and last_a:
            break

    if last_q:
        query_parts.append("ä¸Šä¸€é¡Œï¼š" + last_q[:80])
    if last_a:
        query_parts.append("ä¸Šä¸€ç­”ï¼š" + last_a[:80])

    if resume_info and resume_info.get("skills"):
        query_parts.append("æŠ€èƒ½ï¼š" + ", ".join(resume_info["skills"]))

    rag_query = "ï¼›".join(query_parts)

    # ---- æ ¹æ“šè·ç¼ºè‡ªå‹•æ’åº RAG ----
    role_pref = {
        "å¾Œç«¯å·¥ç¨‹å¸«": ["algorithms", "datastructures", "system_design", "database"],
        "AI å·¥ç¨‹å¸«": ["ai_ml", "algorithms", "computer_arch"],
        "è³‡æ–™å·¥ç¨‹å¸«": ["database", "system_design"],
        "å‰ç«¯å·¥ç¨‹å¸«": ["algorithms", "system_design"],
        "éŸŒé«”å·¥ç¨‹å¸«": ["firmware", "rtos", "driver", "embedded"],
        "ç¡¬é«”å·¥ç¨‹å¸«": ["pcb", "emi", "layout", "analog"],
        "FPGA å·¥ç¨‹å¸«": ["fpga", "rtl", "vhdl", "verilog", "timing"],
        "å°„é »å·¥ç¨‹å¸«": ["rf", "antenna", "emi", "emc"],
        "é›»åŠ›é›»å­å·¥ç¨‹å¸«": ["pfc", "power", "thermal", "converter"],
        "åµŒå…¥å¼ç³»çµ±å·¥ç¨‹å¸«": ["embedded", "linux", "driver", "device tree"],
    }.get(job, [])

    raw_snippets = rag.retrieve(job, rag_query, top_k=5)
    rag_snippets = sorted(
        raw_snippets,
        key=lambda x: any(tag in x.lower() for tag in role_pref),
        reverse=True
    )[:3]

    # ---- System prompt ----
    system_prompt = build_system_prompt(
        job,
        style,
        resume_info=resume_info,
        rag_snippets=rag_snippets
    )

    # ---- Messages ----
    messages = [{"role": "system", "content": system_prompt}]
    for role, content in history:
        messages.append({"role": role, "content": content})

    # ---- å‘¼å« OpenAI ----
    resp = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=messages
    )
    return resp.choices[0].message.content


def parse_json_response(text: str):
    """Parse model output as JSON; try extracting the first {...} block on failure."""
    if not text:
        return None
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        start = text.find("{")
        end = text.rfind("}")
        if start != -1 and end != -1 and end > start:
            try:
                return json.loads(text[start: end + 1])
            except json.JSONDecodeError:
                return None
    return None


def evaluate_auto_end(qa_list, job_role, resume_info=None):
    """
    Use LLM to decide whether to auto-end the interview after the latest answer.
    Returns dict with keys: label, reason, action (end | warn | continue).
    """
    if not qa_list:
        return None

    last_qa = qa_list[-1]
    skills = ", ".join(resume_info.get("skills", [])) if resume_info else ""
    prompt = f"""
ä½ æ˜¯é¢è©¦å®˜çš„åŠ©æ‰‹ï¼Œè«‹åˆ¤æ–·æ˜¯å¦è¦çµæŸé¢è©¦ã€‚è«‹åå‘ã€Œç¹¼çºŒã€ä¸¦çµ¦äºˆæé†’ï¼Œåªæœ‰åœ¨æ˜é¡¯ä¸”åš´é‡çš„æƒ…æ³æ‰çµæŸã€‚æ ¹æ“šæœ€æ–°å›ç­”ï¼Œåˆ¤æ–·ï¼š
- æ˜¯å¦åš´é‡é•åé¢è©¦ç¦®å„€ï¼ˆæŒçºŒæ”»æ“Šæˆ–ç„¡ç¦®ï¼‰ã€‚è¼•å¾®å¤±ç¦®è«‹ç”¨ warnï¼Œä¸è¦ç›´æ¥çµæŸã€‚
- æ˜¯å¦æ˜é¡¯ä¸ç¬¦åˆè·ç¼ºè¦æ±‚ï¼ˆå¤šæ¬¡å›ç­”èˆ‡è·ç¼ºç„¡é—œä¸”ç„¡æ”¹å–„è·¡è±¡ï¼‰ã€‚
- æ˜¯å¦å·²ç¶“è¶³å¤ ç¢ºèªå…¶åˆæ ¼ï¼ˆèƒ½æ›´æ·±å…¥è¿½å•ï¼‰

è«‹ä»¥ JSON è¼¸å‡ºï¼š
{{
  "action": "end" | "warn" | "continue",
  "label": "etiquette" | "unwilling" | "not_qualified" | "qualified" | "continue",
  "reason": "ç°¡çŸ­ä¸­æ–‡ç†ç”±"
}}

è·ç¼ºï¼š{job_role}
å±¥æ­·æŠ€èƒ½ï¼š{skills}
æœ€æ–°æå•ï¼š{last_qa["question"]}
å€™é¸äººå›ç­”ï¼š{last_qa["answer"]}
ç´¯è¨ˆé¡Œæ•¸ï¼š{len(qa_list)}
"""

    resp = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[{"role": "user", "content": prompt}]
    )
    data = parse_json_response(resp.choices[0].message.content)
    if data:
        return {
            "label": data.get("label", "continue"),
            "action": data.get("action", "continue"),
            "reason": data.get("reason", "ç³»çµ±åˆ¤å®š")
        }
    return None


def check_time_limit():
    """Return reason string if time limit exceeded; otherwise None."""
    limit = st.session_state.get("time_limit_minutes")
    start = st.session_state.get("start_time")
    if start and limit:
        elapsed = (datetime.now().timestamp() - start) / 60
        if elapsed >= limit:
            return f"å·²è¶…éè¨­å®šçš„ {int(limit)} åˆ†é˜ï¼Œç³»çµ±è‡ªå‹•çµæŸã€‚"
    return None


# ============================================================
# å ±å‘Šå¼·åŒ–ï¼šæ¨è–¦ç­‰ç´š / é—œéµå­—å‘½ä¸­ / ç°¡å ±å…§å®¹
# ============================================================


def compute_recommendation(overall_scores):
    # å®‰å…¨è½‰æ›ç‚ºæ•¸å­—ï¼Œé¿å… LLM å›å‚³æ–‡å­—é€ æˆéŒ¯èª¤
    vals = []
    for v in overall_scores.values():
        try:
            vals.append(float(v))
        except Exception:
            continue
    if not vals:
        return "On Hold", 0

    avg = sum(vals) / len(vals)
    match_score = round(avg / 5 * 100, 1)
    if avg >= 4.5:
        rec = "Strong Hire"
    elif avg >= 4.0:
        rec = "Hire"
    elif avg >= 3.0:
        rec = "On Hold"
    else:
        rec = "Reject"
    return rec, match_score


ROLE_KEYWORDS = {
    "å¾Œç«¯å·¥ç¨‹å¸«": ["microservices", "REST", "graphql", "ci/cd", "kubernetes", "docker", "database", "redis", "rabbitmq"],
    "AI å·¥ç¨‹å¸«": ["transformer", "llm", "rag", "fine-tune", "pytorch", "tensorflow", "mlops", "vector db"],
    "è³‡æ–™å·¥ç¨‹å¸«": ["etl", "spark", "hadoop", "kafka", "data pipeline", "warehouse", "airflow"],
    "å‰ç«¯å·¥ç¨‹å¸«": ["react", "vue", "typescript", "webpack", "vite", "ui/ux", "accessibility"],
    "éŸŒé«”å·¥ç¨‹å¸«": ["firmware", "rtos", "i2c", "spi", "uart", "ota", "bootloader", "low power"],
    "ç¡¬é«”å·¥ç¨‹å¸«": ["pcb", "s-parameters", "emi", "emc", "esd", "dfm", "dfa", "power integrity", "signal integrity"],
    "FPGA å·¥ç¨‹å¸«": ["fpga", "rtl", "verilog", "vhdl", "timing", "sdc", "pcie", "ddr", "serdes"],
    "å°„é »å·¥ç¨‹å¸«": ["rf", "lna", "pa", "antenna", "vna", "s11", "emi", "emc"],
    "é›»åŠ›é›»å­å·¥ç¨‹å¸«": ["buck", "boost", "pfc", "llc", "switching", "emi", "transformer", "inductor", "thermal"],
    "åµŒå…¥å¼ç³»çµ±å·¥ç¨‹å¸«": ["embedded", "linux", "rtos", "device tree", "driver", "spi", "i2c", "can", "ota"],
}


def compute_keyword_hits(qa_list, role):
    keywords = ROLE_KEYWORDS.get(role, [])
    if not keywords or not qa_list:
        return 0, {}
    all_text = " ".join(x["answer"] for x in qa_list).lower()
    counts = {kw: all_text.count(kw) for kw in keywords}
    total = sum(counts.values())
    return total, counts


def extract_strengths_risks(overall_scores):
    num_scores = {}
    for k, v in overall_scores.items():
        try:
            num_scores[k] = float(v)
        except Exception:
            continue

    strengths = [k for k, v in num_scores.items() if v >= 4.2]
    risks = [k for k, v in num_scores.items() if v <= 3.0]
    name_map = {
        "technical": "æŠ€è¡“æ·±åº¦",
        "communication": "è¡¨é”æ¸…æ™°åº¦",
        "structure": "çµæ§‹åŒ–",
        "relevance": "ç›¸é—œæ€§",
        "problem_solving": "è§£é¡ŒåŠ›",
        "growth_potential": "æˆé•·æ½›åŠ›",
    }
    return [name_map.get(s, s) for s in strengths], [name_map.get(r, r) for r in risks]


def build_brief_eval(overall_summary, strengths, risks):
    parts = []
    parts.append(overall_summary.strip())
    if strengths:
        parts.append("äº®é»åŒ…æ‹¬ï¼š" + "ã€".join(strengths) + "ã€‚")
    if risks:
        parts.append("éœ€æ”¹å–„ï¼š" + "ã€".join(risks) + "ã€‚")
    txt = " ".join(parts)
    words = txt.split()
    if len(words) < 90:
        pad = " æœ¬æ®µç”±ç³»çµ±è‡ªå‹•ç”Ÿæˆï¼Œæ¦‚è¿°å€™é¸äººè¡¨ç¾èˆ‡é¢¨éšªï¼Œä¾› HR å¿«é€Ÿåƒè€ƒã€‚"
        txt += pad
    return txt


def build_improvement_tips(overall_scores, speech_features=None):
    tips = []

    def add(text):
        if text not in tips:
            tips.append(text)

    name_map = {
        "technical": "æŠ€è¡“æ·±åº¦",
        "communication": "è¡¨é”æ¸…æ™°åº¦",
        "structure": "çµæ§‹åŒ–",
        "relevance": "ç›¸é—œæ€§",
        "problem_solving": "è§£é¡ŒåŠ›",
        "growth_potential": "æˆé•·æ½›åŠ›",
    }

    for k, v in overall_scores.items():
        try:
            score = float(v)
        except Exception:
            continue
        label = name_map.get(k, k)
        if k == "technical" and score < 4:
            add(f"{label}ï¼šè£œå¼·æ ¸å¿ƒæŠ€è¡“åŸç†èˆ‡æ¡ˆä¾‹ç´°ç¯€ï¼Œå›ç­”æ™‚åŠ å…¥æ¶æ§‹/æ•ˆèƒ½/å®‰å…¨çš„é‡åŒ–æŒ‡æ¨™ã€‚")
        if k == "communication" and score < 4:
            add(f"{label}ï¼šç²¾ç°¡é–‹å ´ï¼Œå…ˆè¬›çµè«–å†è£œå……èƒŒæ™¯ï¼Œé¿å…å†—é•·é‹ªé™³ã€‚")
        if k == "structure" and score < 4:
            add(f"{label}ï¼šæ¡ç”¨ STAR / PREP çµæ§‹æ‹†è§£ï¼Œå…ˆåˆ—æ­¥é©Ÿæˆ–è¦é»å†å±•é–‹ã€‚")
        if k == "relevance" and score < 4:
            add(f"{label}ï¼šå›æ‰£è·ç¼ºéœ€æ±‚èˆ‡æƒ…å¢ƒï¼Œé¿å…é›¢é¡Œï¼Œçµå°¾è£œä¸€å¥èˆ‡ç›®æ¨™çš„é€£çµã€‚")
        if k == "problem_solving" and score < 4:
            add(f"{label}ï¼šèªªæ¸…æ¥šå‡è¨­ã€é¢¨éšªèˆ‡æ¬Šè¡¡ï¼Œæè¿°ä½ å¦‚ä½•é©—è­‰æˆ– rollbackã€‚")
        if k == "growth_potential" and score < 4:
            add(f"{label}ï¼šè£œå……è¿‘æœŸå­¸ç¿’æˆ– side projectï¼Œå±•ç¾è‡ªæˆ‘é©…å‹•èˆ‡è¿­ä»£ã€‚")

    if speech_features:
        if speech_features.get("silence_ratio", 0) > 0.25:
            add("å£èªåœé “åå¤šï¼šæå‰åˆ—æç¶±ã€ç”¨çŸ­å¥å›ç­”ï¼Œé¿å…é•·æ™‚é–“ç©ºç™½ã€‚")
        if speech_features.get("filler_ratio", 0) > 0.05:
            add("å¡«å……è©åå¤šï¼šç·´ç¿’åœé “æ›¿ä»£ã€å—¯ã€å‘ƒã€ï¼Œç”¨ã€è®“æˆ‘ç¢ºèªä¸€ä¸‹é‡é»ã€éæ¸¡ã€‚")
        if speech_features.get("volume_stability", 1) < 0.6:
            add("éŸ³é‡ç©©å®šåº¦ä¸è¶³ï¼šä¿æŒä¸­ä½é€Ÿã€é™ä½æƒ…ç·’æ³¢å‹•ï¼Œè®“é‡é»æ›´æ¸…æ¥šã€‚")

    if not tips:
        tips.append("æ•´é«”è¡¨ç¾å‡è¡¡ï¼Œç¶­æŒç›®å‰å›ç­”æ¡†æ¶å³å¯ã€‚")

    return tips


def is_brief_greeting(text: str) -> bool:
    """Detect very short greetings to avoid over-penalizing etiquette."""
    if not text:
        return False
    t = text.strip().lower()
    greetings = ["hi", "hello", "hey", "ä½ å¥½", "å—¨", "æ‚¨å¥½"]
    if len(t) <= 12 and any(g in t for g in greetings):
        return True
    words = t.split()
    return len(words) <= 3 and any(g in t for g in greetings)


def end_interview(reason_label="manual", reason_detail=None):
    """Run grading once and store auto-end reason."""
    if st.session_state.get("grade_result"):
        return
    if not st.session_state.qa_list:
        st.warning("ä½ å°šæœªå›ç­”ä»»ä½•é¡Œç›®ï¼Œç„¡æ³•é€²è¡Œè©•åˆ†ã€‚")
        return

    result = grade_interview(
        st.session_state.qa_list,
        st.session_state.job_role if "job_role" in st.session_state else None,
        st.session_state.resume_info,
        speech_features=st.session_state.last_speech_features
    )

    st.session_state.grade_result = result
    st.session_state.started = False
    st.session_state.auto_end_reason = reason_detail or reason_label

    if st.session_state.candidate_id:
        interview_id = save_interview(
            candidate_id=st.session_state.candidate_id,
            job_role=st.session_state.job_role if "job_role" in st.session_state else "",
            timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            summary=result["overall"]["summary"],
        )

        for qa in st.session_state.qa_list:
            save_qa(interview_id, qa["question"], qa["answer"])

        save_scores(interview_id, result["overall"])


# ============================================================
# PART 3 â€” é¢è©¦æµç¨‹ï¼ˆé–‹å§‹é¢è©¦ + èªéŸ³å›ç­” + TTS + Whisperï¼‰
# ============================================================

# ------------------------------------------------------------
# é¡¯ç¤ºæ­·å²å°è©±è¨Šæ¯
# ------------------------------------------------------------
for role, content in st.session_state.messages:
    st.chat_message(role).markdown(content)


# ------------------------------------------------------------
# å°šæœªé–‹å§‹é¢è©¦
# ------------------------------------------------------------
if not st.session_state.started:

    if st.button("â–¶ï¸ é–‹å§‹é¢è©¦"):

        # ç”Ÿæˆç¬¬ä¸€é¡Œï¼ˆé€šå¸¸æ˜¯è‡ªæˆ‘ä»‹ç´¹ï¼‰
        first_reply = call_llm(
            job_role,
            interview_style,
            [],
            resume_info=st.session_state.resume_info
        )

        st.session_state.messages.append(("assistant", first_reply))
        st.session_state.last_question = first_reply
        st.session_state.started = True
        st.session_state.start_time = datetime.now().timestamp()
        st.session_state.grade_result = None
        st.session_state.auto_end_reason = None
        st.session_state.last_audio_hash = None
        st.session_state.etiquette_strikes = 0
        st.session_state.qualified_streak = 0

        # â­ é—œéµï¼šç¬¬ä¸€é¡Œ TTS å¿…é ˆå»¶å¾Œä¸€è¼ªæ’­æ”¾
        if st.session_state.voice_mode:
            st.session_state.play_tts_first_question = True

        st.rerun()


# ------------------------------------------------------------
# ç¬¬ä¸€é¡Œ TTS æ’­æ”¾ï¼ˆé¿å…è¢« rerun åƒæ‰ï¼‰
# ------------------------------------------------------------
if st.session_state.get("play_tts_first_question", False):
    st.session_state.play_tts_first_question = False   # æ’­ä¸€æ¬¡å°±é—œæ‰

    text = st.session_state.last_question
    audio_bytes = synthesize_speech(text)
    if audio_bytes:
        st.audio(audio_bytes, format="audio/mp3")


# ------------------------------------------------------------
# é¢è©¦å·²ç¶“é–‹å§‹ â†’ ä½¿ç”¨è€…å›ç­”ï¼ˆèªéŸ³ / æ–‡å­—ï¼‰
# ------------------------------------------------------------
if st.session_state.started:

    # æ™‚é–“åˆ°è‡ªå‹•çµæŸï¼ˆæœ‰ä½œç­”æ‰è©•åˆ†ï¼‰
    if not st.session_state.get("grade_result"):
        time_reason = check_time_limit()
        if time_reason and st.session_state.qa_list:
            end_interview("time_limit", time_reason)
            st.info(time_reason)
            st.rerun()

    st.markdown("### ğŸ§‘â€ğŸ’¬ è«‹å›ç­”ï¼š")

    # èªéŸ³éŒ„è£½èˆ‡æ–‡å­—è¼¸å…¥ä¸Šä¸‹æ’åˆ—ï¼Œç¶­æŒåœ¨åŒä¸€å€å¡Š
    voice_answer = None

    st.markdown("#### ğŸ¤ èªéŸ³éŒ„éŸ³")
    audio_rec = st.audio_input(
        "é»æ“ŠéŒ„éŸ³é–‹å§‹ä½œç­”",
        label_visibility="collapsed",
    )

    st.markdown("#### ğŸ“ æ–‡å­—å›ç­”")
    text_answer = st.chat_input("è«‹è¼¸å…¥ä½ çš„å›ç­”â€¦", key="text_answer")

    if audio_rec:
        audio_bytes = audio_rec.getvalue()
        audio_hash = hashlib.md5(audio_bytes).hexdigest()

        if audio_hash != st.session_state.last_audio_hash:
            with st.spinner("Whisper æ­£åœ¨è¾¨è­˜èªéŸ³â€¦"):
                whisper_resp = speech_to_text(audio_rec)

            voice_answer = whisper_resp["text"]

            # ===== èªéŸ³ç‰¹å¾µåˆ†æ =====
            speech_features = analyze_speech_features(
                whisper_resp, audio_bytes)
            st.session_state.last_speech_features = speech_features
            st.session_state.last_audio_hash = audio_hash

            st.success("èªéŸ³è¾¨è­˜å®Œæˆï¼")
        else:
            st.info("é€™æ®µéŒ„éŸ³å·²è™•ç†éï¼Œæœªé‡è¤‡é€å‡ºã€‚")

    user_input = voice_answer if voice_answer else text_answer

    if user_input:

        # --------- è¨˜éŒ„ä¸Šä¸€é¡Œ+ä½¿ç”¨è€…å›ç­”ï¼ˆQAï¼‰ -----------
        st.session_state.qa_list.append({
            "question": st.session_state.last_question,
            "answer": user_input
        })

        st.session_state.messages.append(("user", user_input))
        st.chat_message("user").markdown(user_input)

        # --------- æª¢æŸ¥æ˜¯å¦è‡ªå‹•çµæŸ ----------
        proceed_with_question = True
        decision = evaluate_auto_end(
            st.session_state.qa_list,
            job_role,
            st.session_state.resume_info
        )
        # time limit is handled above; here handle etiquette/fit logic
        if decision:
            label = decision.get("label")
            action = decision.get("action")
            reason = decision.get("reason", "")

            if label == "etiquette":
                # æ¯æ¬¡é•åç¦®å„€éƒ½ç´¯è¨ˆï¼Œæ»¿ 3 æ¬¡è‡ªå‹•çµæŸ
                st.session_state.etiquette_strikes += 1
                strikes = st.session_state.etiquette_strikes
                if strikes >= 3 and action == "end":
                    end_interview(
                        "etiquette", f"ç¬¬ {strikes} æ¬¡é•åç¦®å„€ï¼š{reason or 'å¤šæ¬¡ç°¡çŸ­/ä¸ç¦®è²Œå›è¦†'}")
                    st.info(f"é¢è©¦å·²è‡ªå‹•çµæŸï¼š{reason or 'å¤šæ¬¡é•åç¦®å„€'}")
                    st.rerun()
                else:
                    st.warning(
                        f"æ³¨æ„é¢è©¦ç¦®å„€ï¼ˆ{strikes}/3ï¼‰ï¼š{reason or 'è«‹æä¾›å®Œæ•´ã€è‡ªä¿¡çš„å›è¦†ã€‚'}")
                proceed_with_question = False  # è®“ä½¿ç”¨è€…é‡æ–°ä½œç­”ï¼Œä¸è¦ä¸­æ–· app

            elif label == "qualified":
                st.session_state.qualified_streak += 1
                if st.session_state.qualified_streak >= 10:
                    end_interview("offer", "é€£çºŒ 10 é¡Œç¬¦åˆæ¨™æº–ï¼Œæ­å–œç²å¾—éŒ„ç”¨ï¼")
                    st.success("æ­å–œï¼ä½ å·²ç²å¾—éŒ„ç”¨ï¼Œé¢è©¦çµæŸã€‚")
                    st.rerun()
                # continue asking deeper questions automatically

            elif action == "end" and label in ("unwilling", "not_qualified"):
                end_interview(label, reason)
                st.info(f"é¢è©¦å·²è‡ªå‹•çµæŸï¼š{reason}")
                st.rerun()

        if proceed_with_question:
            # --------- å‘¼å«é¢è©¦å®˜å–å¾—ä¸‹ä¸€é¡Œ ----------
            assistant_reply = call_llm(
                job_role,
                interview_style,
                st.session_state.messages,
                resume_info=st.session_state.resume_info,
            )

            st.session_state.messages.append(("assistant", assistant_reply))
            st.chat_message("assistant").markdown(assistant_reply)
            st.session_state.last_question = assistant_reply

            # --------- TTS æ’­æ”¾ä¸‹ä¸€é¡Œ ----------
            if st.session_state.voice_mode:
                tts_audio = synthesize_speech(assistant_reply)
                if tts_audio:
                    st.audio(tts_audio, format="audio/mp3")

# ============================================================
# PART 4 â€” AI é¢è©¦è©•åˆ†ï¼ˆå«èªéŸ³ç‰¹å¾µ + èªéŸ³å»ºè­°ï¼‰
# ============================================================

# ------------------------------------------------------------
# è©•åˆ†æŒ‰éˆ•
# ------------------------------------------------------------
st.markdown("---")
st.subheader("ğŸ“Š é¢è©¦è©•åˆ†ï¼ˆAI åˆ†æï¼‰")

if st.button("ğŸ“Š çµæŸé¢è©¦ä¸¦é€²è¡Œ AI è©•åˆ†"):

    if st.session_state.grade_result:
        st.info("æœ¬æ¬¡é¢è©¦å·²å®Œæˆè©•åˆ†ã€‚")
    else:
        with st.spinner("AI æ­£åœ¨åˆ†æä½ çš„æ•´å ´é¢è©¦â€¦â€¦"):
            end_interview("manual", "æ‰‹å‹•çµæŸé¢è©¦")

        st.success("è©•åˆ†å®Œæˆï¼å‘ä¸‹æ²å‹•æŸ¥çœ‹åˆ†æçµæœã€‚")


# ------------------------------------------------------------
# é¡¯ç¤ºè©•åˆ†çµæœ
# ------------------------------------------------------------
if (
    not st.session_state.grade_result
    and st.session_state.qa_list
    and not st.session_state.started
):
    # è‹¥å·²åœæ­¢é¢è©¦ä½†å°šæœªå¯«å…¥è©•åˆ†ï¼Œè£œç®—ä¸€æ¬¡
    end_interview("manual", "ç³»çµ±è‡ªå‹•è£œç®—è©•åˆ†")

if st.session_state.grade_result:

    result = st.session_state.grade_result
    overall = result["overall"]
    per_question = result["per_question"]

    tech = overall["technical"]
    comm = overall["communication"]
    struct = overall["structure"]
    rel = overall["relevance"]
    ps = overall["problem_solving"]
    gp = overall["growth_potential"]

    sf = st.session_state.last_speech_features
    from grader import generate_speech_feedback

    # Report metadata derived from scores/keywords
    rec, match_score = compute_recommendation(overall)
    _, kw_detail = compute_keyword_hits(st.session_state.qa_list, job_role)
    strengths, risks = extract_strengths_risks(overall)
    brief_eval = build_brief_eval(overall["summary"], strengths, risks)
    improvement_tips = build_improvement_tips(overall, sf)

    def speech_brief(features):
        if not features:
            return "æœªæä¾›èªéŸ³ï¼Œç„¡æ³•é€²è¡Œå£èªåˆ†æã€‚"
        wpm = features.get("wpm", 0)
        silence = features.get("silence_ratio", 0)
        filler = features.get("filler_ratio", 0)
        stability = features.get("volume_stability", 0)
        parts = []
        # æµæš¢åº¦
        if 80 <= wpm <= 180:
            parts.append("èªé€Ÿåœ¨å¯ç†è§£ç¯„åœï¼Œæµæš¢åº¦è‰¯å¥½")
        elif wpm < 80:
            parts.append("èªé€Ÿåæ…¢ï¼Œéœ€åŠ å¿«ç¯€å¥é¿å…å†—é•·")
        else:
            parts.append("èªé€Ÿåå¿«ï¼Œå»ºè­°æ”¾æ…¢ä»¥ä¾¿ç†è§£")
        # åœé “èˆ‡è´…è©
        if silence > 0.25:
            parts.append("åœé “æ¯”ä¾‹åé«˜ï¼Œå»ºè­°å…ˆçµ„ç¹”å†å›ç­”")
        if filler > 0.05:
            parts.append("å¡«å……è©è¼ƒå¤šï¼Œå½±éŸ¿å°ˆæ¥­æ„Ÿ")
        # éŸ³é‡ç©©å®šåº¦
        if stability < 0.6:
            parts.append("éŸ³é‡èµ·ä¼è¼ƒå¤§ï¼Œéœ€æå‡ç©©å®šåº¦")
        else:
            parts.append("éŸ³é‡ç©©å®šåº¦å°šå¯")
        return "ï¼›".join(parts)

    st.markdown("## ğŸ“Š é¢è©¦åˆ†æçµæœ")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("åŒ¹é…åˆ†æ•¸", f"{match_score}/100")
    c2.metric("AI å»ºè­°", rec)
    c3.metric("é¡Œç›®æ•¸", len(per_question))
    c4.metric("èªéŸ³æ¨£æœ¬", "æœ‰" if sf else "ç„¡")

    def build_report_md():
        lines = []
        lines.append("# AI é¢è©¦è©•ä¼°å ±å‘Š")
        lines.append(f"- å ±å‘Šç”Ÿæˆæ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M')}")
        lines.append(f"- å€™é¸äººï¼š{st.session_state.candidate_id}")
        lines.append(f"- æ‡‰å¾µè·ä½ï¼š{job_role}")
        if st.session_state.auto_end_reason:
            lines.append(f"- çµæŸåŸå› ï¼š{st.session_state.auto_end_reason}")
        lines.append("")

        # 1. æ‘˜è¦ç¸½è¦½ï¼ˆå…¨ä¸­æ–‡ï¼‰
        lines.append("## 1. æ‘˜è¦ç¸½è¦½")
        lines.append(f"- AI ç¸½é«”å»ºè­°ï¼š{rec}")
        lines.append(f"- æ•´é«”åŒ¹é…åˆ†æ•¸ï¼š{match_score}/100")
        lines.append(f"- ä¸»è¦å„ªå‹¢ï¼š{', '.join(strengths) if strengths else 'ç„¡æ˜é¡¯å„ªå‹¢'}")
        lines.append(f"- æ½›åœ¨é¢¨éšªï¼š{', '.join(risks) if risks else 'ç„¡æ˜é¡¯é¢¨éšª'}")
        lines.append(f"- AI ç°¡è¿°ï¼š{brief_eval}")
        lines.append("")

        # 2. æŠ€è¡“èƒ½åŠ›ï¼ˆä»¥ç¾æœ‰è¨Šè™Ÿåš RAG Proxyï¼‰
        kw_hits_total = sum(kw_detail.values()) if kw_detail else 0
        lines.append("## 2. æŠ€è¡“èƒ½åŠ›è©•ä¼°ï¼ˆRAG è¿‘ä¼¼ï¼‰")
        lines.append(f"- æº–ç¢ºåº¦ï¼ˆä»¥ Relevance ä»£è¡¨ï¼‰ï¼š{rel}/5")
        lines.append(f"- æ·±åº¦ï¼ˆä»¥ Technical ä»£è¡¨ï¼‰ï¼š{tech}/5")
        lines.append(f"- çµæ§‹åŒ–è¡¨é”ï¼ˆStructureï¼‰ï¼š{struct}/5")
        lines.append(f"- é—œéµå­—å‘½ä¸­æ•¸ï¼š{kw_hits_total}")
        if kw_detail and any(v > 0 for v in kw_detail.values()):
            lines.append("- é—œéµå­—æ˜ç´°ï¼š")
            for k, v in sorted(kw_detail.items(), key=lambda kv: kv[1], reverse=True):
                if v > 0:
                    lines.append(f"  - {k}ï¼š{v}")
        else:
            lines.append("- é—œéµå­—æ˜ç´°ï¼šå°šæœªåµæ¸¬åˆ°å‘½ä¸­")
        lines.append(f"- é¢è©¦ç­”é¡Œæ¨£æœ¬æ•¸ï¼š{len(per_question)}")
        lines.append("")

        # 3. è»Ÿå¯¦åŠ› / è¡Œç‚ºè¡¨ç¾ï¼ˆèªéŸ³ç‰¹å¾µï¼‰
        lines.append("## 3. è»Ÿå¯¦åŠ›èˆ‡è¡Œç‚ºè¡¨ç¾ï¼ˆèªéŸ³ï¼‰")
        lines.append(f"- æºé€šè¡¨ç¾ï¼ˆæ•´é«”ï¼‰ï¼š{comm}/5")
        if sf:
            lines.append(f"- èªé€Ÿ WPMï¼š{sf['wpm']}")
            lines.append(f"- éœéŸ³æ¯”ä¾‹ï¼š{sf['silence_ratio']}")
            lines.append(f"- è´…è©æ¯”ä¾‹ï¼š{sf['filler_ratio']}")
            lines.append(f"- éŸ³é‡ç©©å®šåº¦ï¼š{sf['volume_stability']}")
            lines.append(f"- å£èªè¡¨ç¾ç¸½çµï¼š{speech_brief(sf)}")
            lines.append("- æƒ…ç·’èˆ‡æ…‹åº¦ï¼šç›®å‰æœªå•Ÿç”¨æƒ…ç·’/è¡¨æƒ…åˆ†æï¼ˆæš«ä¸æä¾›ï¼‰")
            lines.append("- èªéŸ³å»ºè­°ï¼ˆAIï¼‰ï¼š")
            lines.append(generate_speech_feedback(sf))
        else:
            lines.append("- èªéŸ³ç‰¹å¾µï¼šæœªæä¾›èªéŸ³ï¼Œç„¡æ³•åˆ†æ")
            lines.append("- æƒ…ç·’èˆ‡æ…‹åº¦ï¼šæœªåµæ¸¬")
            lines.append(f"- å£èªè¡¨ç¾ç¸½çµï¼š{speech_brief(sf)}")
        lines.append("")

        # 4. æ”¹é€²å»ºè­°
        lines.append("## 4. æ”¹é€²å»ºè­°ï¼ˆAIï¼‰")
        for tip in improvement_tips:
            lines.append(f"- {tip}")
        lines.append("")

        # 5. é¡Œç›®é€é¡Œåˆ†æ
        lines.append("## 5. é¡Œç›®é€é¡Œåˆ†æ Question-by-Question")
        for i, item in enumerate(per_question, 1):
            s = item['score']
            lines.append(f"### é¡Œç›® {i}")
            lines.append(f"- å•é¡Œï¼š{item['question']}")
            lines.append(f"- å›ç­”ï¼š{item['answer']}")
            lines.append(
                f"- è©•åˆ† Technical {s['technical']}/5ï¼Œ"
                f"Communication {s['communication']}/5ï¼Œ"
                f"Structure {s['structure']}/5ï¼Œ"
                f"Relevance {s['relevance']}/5ï¼Œ"
                f"Problem Solving {s['problem_solving']}/5ï¼Œ"
                f"Growth Potential {s['growth_potential']}/5"
            )
            lines.append(f"- AI å›é¥‹ï¼š{item['feedback']}")
            lines.append("")

        # 6. é™„éŒ„ / åŸå§‹è³‡æ–™
        lines.append("## 6. é™„éŒ„èˆ‡åŸå§‹åˆ†æ•¸")
        lines.append(f"- Overall Technicalï¼š{tech}")
        lines.append(f"- Overall Communicationï¼š{comm}")
        lines.append(f"- Overall Structureï¼š{struct}")
        lines.append(f"- Overall Relevanceï¼š{rel}")
        lines.append(f"- Overall Problem Solvingï¼š{ps}")
        lines.append(f"- Overall Growth Potentialï¼š{gp}")
        lines.append(f"- ç³»çµ±æ‘˜è¦ï¼š{overall['summary']}")

        return "\n".join(lines)

    report_md = build_report_md()

    st.markdown(report_md)

    st.subheader("ğŸ™ï¸ èªéŸ³åˆ†æ")
    if sf:
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("èªé€Ÿ WPM", sf.get("wpm"))
        c2.metric("éœéŸ³æ¯”ä¾‹", sf.get("silence_ratio"))
        c3.metric("è´…è©æ¯”ä¾‹", sf.get("filler_ratio"))
        c4.metric("éŸ³é‡ç©©å®šåº¦", sf.get("volume_stability"))
        st.markdown(f"- å£èªè¡¨ç¾ç¸½çµï¼š{speech_brief(sf)}")
        st.markdown("**AI èªéŸ³å»ºè­°**")
        st.markdown(generate_speech_feedback(sf))
    else:
        st.info("æœ¬æ¬¡æœªæä¾›èªéŸ³ï¼Œç„¡æ³•ç”¢ç”ŸèªéŸ³å ±å‘Šã€‚è«‹éŒ„è£½èªéŸ³ä½œç­”ä»¥ç²å¾—å£èªåˆ†æã€‚")

    import tempfile
    image_paths = []

    categories = ["technical", "communication", "structure",
                  "relevance", "problem_solving", "growth_potential"]
    labels_zh = ["æŠ€è¡“", "è¡¨é”", "çµæ§‹", "ç›¸é—œ", "è§£é¡Œ", "æˆé•·"]
    scores = [tech, comm, struct, rel, ps, gp]
    values = scores + scores[:1]
    angles = np.linspace(0, 2*np.pi, len(categories) + 1)

    fig_dl, ax_dl = plt.subplots(figsize=(6, 6), subplot_kw={"polar": True})
    ax_dl.plot(angles, values, linewidth=2)
    ax_dl.fill(angles, values, alpha=0.25)
    ax_dl.set_thetagrids(angles[:-1] * 180/np.pi, labels_zh)
    ax_dl.set_ylim(0, 5)
    ax_dl.set_yticks([1, 2, 3, 4, 5])
    plt.tight_layout()
    st.pyplot(fig_dl)
    with tempfile.NamedTemporaryFile(delete=False, suffix=".png") as img_tmp:
        fig_dl.savefig(img_tmp.name, bbox_inches="tight")
        image_paths.append(img_tmp.name)
    plt.close(fig_dl)

    if st.session_state.selected_history_interview_id:
        ref_scores = get_scores(st.session_state.selected_history_interview_id)
        if ref_scores:
            ref_vals = [
                ref_scores['technical'],
                ref_scores['communication'],
                ref_scores['structure'],
                ref_scores['relevance'],
                ref_scores['problem_solving'],
                ref_scores['growth_potential'],
            ]
            ref_plot = ref_vals + ref_vals[:1]
            cur_plot = values

            fig_cmp, ax_cmp = plt.subplots(
                figsize=(6, 6), subplot_kw={"polar": True})
            ax_cmp.plot(angles, ref_plot, "r--", linewidth=1.8, label="æ­·å²ç´€éŒ„")
            ax_cmp.plot(angles, cur_plot, "b-", linewidth=2.2, label="æœ¬æ¬¡çµæœ")
            ax_cmp.fill(angles, cur_plot, alpha=0.25)
            ax_cmp.set_thetagrids(angles[:-1] * 180/np.pi, labels_zh)
            ax_cmp.set_ylim(0, 5)
            ax_cmp.legend(loc="upper right", bbox_to_anchor=(1.25, 1.12))
            plt.tight_layout()
            st.pyplot(fig_cmp)
            with tempfile.NamedTemporaryFile(delete=False, suffix=".png") as img_tmp2:
                fig_cmp.savefig(img_tmp2.name, bbox_inches="tight")
                image_paths.append(img_tmp2.name)
            plt.close(fig_cmp)

    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
        export_pdf(tmp.name, report_md, image_paths=image_paths)
        with open(tmp.name, "rb") as f:
            pdf_bytes = f.read()

    html_content = export_html(report_md)

    dl1, dl2, dl3 = st.columns(3)
    with dl1:
        st.download_button(
            "â¬‡ï¸ ä¸‹è¼‰ Markdown å ±å‘Š",
            data=report_md,
            file_name="interview_report.md",
            mime="text/markdown",
        )
    with dl2:
        st.download_button(
            "â¬‡ï¸ ä¸‹è¼‰ PDF å ±å‘Š",
            data=pdf_bytes,
            file_name="interview_report.pdf",
            mime="application/pdf",
        )
    with dl3:
        st.download_button(
            "â¬‡ï¸ ä¸‹è¼‰ HTML å ±å‘Š",
            data=html_content,
            file_name="interview_report.html",
            mime="text/html",
        )
