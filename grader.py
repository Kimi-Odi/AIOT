# ================================================================
# grader.py â€” AI è™›æ“¬é¢è©¦å®˜è©•åˆ†æ¨¡çµ„ï¼ˆå«èªéŸ³ç‰¹å¾µèª¿æ•´ + èªéŸ³æ”¹å–„å»ºè­°ï¼‰
# ================================================================

import os
import json
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ================================================================
# ğŸ”¹ èªéŸ³ç‰¹å¾µèª¿æ•´ï¼ˆB åŠŸèƒ½ï¼‰
# ================================================================


def speech_feature_adjustment(features):
    if not features:
        return 1.0

    wpm = features["wpm"]
    silence = features["silence_ratio"]
    stability = features["volume_stability"]
    filler = features["filler_ratio"]

    # èªé€Ÿ
    if wpm < 80:
        wpm_score = 0.7
    elif 80 <= wpm <= 180:
        wpm_score = 1.0
    else:
        wpm_score = 0.8

    # åœé “
    if silence < 0.1:
        silence_score = 1.0
    elif silence < 0.25:
        silence_score = 0.85
    else:
        silence_score = 0.65

    # éŸ³é‡ç©©å®šåº¦
    stability_score = min(max(stability, 0), 1)

    # å¡«å……è©
    if filler < 0.02:
        filler_score = 1.0
    elif filler < 0.05:
        filler_score = 0.8
    else:
        filler_score = 0.65

    final = (wpm_score + silence_score + stability_score + filler_score) / 4
    return round(final, 3)

# ================================================================
# ğŸ”¹ èªéŸ³æ”¹å–„å»ºè­°ï¼ˆD åŠŸèƒ½ï¼‰
# ================================================================


def generate_speech_feedback(features):
    if not features:
        return "æœ¬æ¬¡æœªæä¾›èªéŸ³å›ç­”ï¼Œå› æ­¤ç„¡æ³•ç”¢ç”ŸèªéŸ³è¡¨é”å»ºè­°ã€‚"

    wpm = features["wpm"]
    silence = features["silence_ratio"]
    stability = features["volume_stability"]
    filler = features["filler_ratio"]

    fb = []

    if wpm < 100:
        fb.append(f"- èªé€Ÿ {wpm} WPMï¼šåæ…¢ï¼Œå¯æå‡æµæš¢åº¦ã€‚")
    elif wpm > 180:
        fb.append(f"- èªé€Ÿ {wpm} WPMï¼šåå¿«ï¼Œå»ºè­°æ”¾æ…¢èªå¥ã€‚")
    else:
        fb.append(f"- èªé€Ÿ {wpm} WPMï¼šè¡¨ç¾è‰¯å¥½ã€‚")

    if silence > 0.25:
        fb.append(f"- åœé “æ¯”ä¾‹ {silence}ï¼šåœé “åå¤šï¼Œå¯å…ˆçµ„ç¹”å¥å­å†å›ç­”ã€‚")
    else:
        fb.append(f"- åœé “æ¯”ä¾‹ {silence}ï¼šè‡ªç„¶ã€‚")

    if stability < 0.6:
        fb.append(f"- éŸ³é‡ç©©å®šåº¦ {stability}ï¼šéŸ³é‡èµ·ä¼æ˜é¡¯ï¼Œå¯åŠ å¼·ç©©å®šã€‚")
    else:
        fb.append(f"- éŸ³é‡ç©©å®šåº¦ {stability}ï¼šè‰¯å¥½ã€‚")

    if filler > 0.05:
        fb.append(f"- å¡«å……è©æ¯”ä¾‹ {filler}ï¼šå£é ­ç¦ªåå¤šï¼Œå¯ç·´ç¿’é¿å…ã€‚")
    else:
        fb.append(f"- å¡«å……è©æ¯”ä¾‹ {filler}ï¼šæ­£å¸¸ã€‚")

    fb.append("\nå»ºè­°æ¯å¤©éŒ„éŸ³ç·´ç¿’ 3~5 åˆ†é˜ï¼Œæœƒæ˜é¡¯æ”¹å–„å£èªè¡¨é”ã€‚")

    return "\n".join(fb)

# ================================================================
# ğŸ”¹ é€é¡Œè©•åˆ†
# ================================================================


def grade_single_qa(question, answer, speech_features=None):
    def parse_json_response(text):
        """
        Try to parse the model output as JSON; fall back to extracting the first
        {...} block when strict parsing fails.
        """
        if not text:
            return None
        try:
            return json.loads(text)
        except json.JSONDecodeError:
            pass

        start = text.find("{")
        end = text.rfind("}")
        if start != -1 and end != -1 and end > start:
            try:
                return json.loads(text[start : end + 1])
            except json.JSONDecodeError:
                return None
        return None

    prompt = f"""
ä½ æ˜¯ä¸€ä½å°ˆæ¥­é¢è©¦å®˜ï¼Œè«‹é‡å°å€™é¸äººçš„å›ç­”é€²è¡Œé€é¡Œè©•åˆ†ï¼ˆ1~5 åˆ†ï¼Œå¯å«å°æ•¸ï¼‰ã€‚

é¡Œç›®ï¼š{question}
å›ç­”ï¼š{answer}

è«‹ä»¥ JSON å›å‚³ï¼š
{{
  "technical": x,
  "communication": x,
  "structure": x,
  "relevance": x,
  "problem_solving": x,
  "growth_potential": x,
  "feedback": "ä¸€å¥è©±å›é¥‹"
}}
"""

    resp = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[{"role": "user", "content": prompt}]
    )

    content = resp.choices[0].message.content
    data = parse_json_response(content)
    if not data:
        # Provide safe defaults so grading doesn't crash if JSON parsing fails.
        data = {
            "technical": 3,
            "communication": 3,
            "structure": 3,
            "relevance": 3,
            "problem_solving": 3,
            "growth_potential": 3,
            "feedback": content.strip() if content else "ï¼ˆæ¨¡å‹å›è¦†ç„¡æ³•è§£æç‚º JSONï¼‰",
        }
    # clamp and format scores to 1~5 with decimals
    for k in ["technical", "communication", "structure", "relevance", "problem_solving", "growth_potential"]:
        try:
            data[k] = max(1, min(5, float(data[k])))
        except Exception:
            data[k] = 1.0

    # â­ å°‡èªéŸ³ç‰¹å¾µåŠ æ¬Š
    if speech_features:
        factor = speech_feature_adjustment(speech_features)
        data["communication"] = round(data["communication"] * factor, 2)
        data["structure"] = round(data["structure"] * (0.7 + factor * 0.3), 2)

    return data

# ================================================================
# ğŸ”¹ æ•´å ´é¢è©¦è©•åˆ†
# ================================================================


def grade_interview(qa_list, job_role, resume_info=None, speech_features=None):

    per_question = []

    for qa in qa_list:
        score = grade_single_qa(
            qa["question"],
            qa["answer"],
            speech_features=speech_features
        )
        per_question.append({
            "question": qa["question"],
            "answer": qa["answer"],
            "score": score,
            "feedback": score["feedback"]
        })

    n = len(per_question)
    overall = {
        "technical": 0,
        "communication": 0,
        "structure": 0,
        "relevance": 0,
        "problem_solving": 0,
        "growth_potential": 0,
    }

    for item in per_question:
        s = item["score"]
        for key in overall:
            overall[key] += s[key]

    for key in overall:
        overall[key] = round(overall[key] / n, 2)

    # æ•´é«”è©•è«–ï¼ˆLLMï¼‰
    summary_prompt = f"""
æ ¹æ“šä»¥ä¸‹åˆ†æ•¸ï¼ˆ1~5ï¼‰æ’°å¯«ä¸€æ®µ 3~5 å¥çš„æ•´é«”è©•è«–ï¼ˆç¹é«”ä¸­æ–‡ï¼‰ï¼š

è·ç¼ºï¼š{job_role}
åˆ†æ•¸ï¼š{overall}

è«‹çµ¦æµæš¢æ®µè½ï¼Œä¸éœ€åˆ—é»ã€‚
"""

    resp = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[{"role": "user", "content": summary_prompt}]
    )

    overall["summary"] = resp.choices[0].message.content.strip()

    return {
        "overall": overall,
        "per_question": per_question
    }
